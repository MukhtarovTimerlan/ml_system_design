# ML System Design Document — News Assistant AI

## 1. Зачем идём в разработку продукта?
Поток новостей растёт очень быстро, и пользователям сложно ориентироваться в большом количестве материалов из разных Telegram-каналов.  
Большие AI-ассистенты умеют отвечать на вопросы, но почти никогда не дают **прозрачных ссылок на источники** и часто «галлюцинируют».  

Цель проекта — создать локальный ассистент, который:
- работает на приватных данных (локальный хост);
- даёт точные ответы по реальным новостям из Telegram;
- всегда показывает цитаты и ссылки на фрагменты новостей;
- предоставляет простой интерфейс через Streamlit.

Такой продукт помогает быстро получать достоверные сведения из множества источников и экономит время на анализ новостного фона.

---

## 2. Бизнес-требования и ограничения

### 2.1 Бизнес-требования
1. **Актуальность контента:**  
   Ассистент должен уметь работать с большим новостным архивом (3+ млн записей) и обеспечивать поиск наиболее релевантных материалов.
2. **Прозрачность:**  
   Каждое утверждение в ответе должно быть привязано к конкретным цитатам из Telegram-постов.
3. **Удобство для пользователя:**  
   Интерфейс (Streamlit) должен быть простым: поле для запроса, сгенерированный ответ, список использованных источников.
4. **Возможность локального развёртывания:**  
   Приложение запускается на локальной машине без сторонних API для inference.
5. **Масштабируемость:**  
   Система должна позволять добавлять новые Telegram-каналы или обновлять базу.

### 2.2 Ограничения
1. **Локальные ресурсы:**  
   Обработка 3+ млн записей может требовать оптимизации индекса, батчевой загрузки и экономного использования памяти.
2. **Ограничения Telegram API:**  
   - Ограничения по частоте запросов.  
   - Не все каналы дают доступ через API.  
   - Полная ретроспектива сообщений может быть недоступна онлайн (но у нас уже есть дамп).
3. **Модель должна быть достаточно лёгкой**, чтобы работать локально (например, 7B / 8B моделей).
4. **Предпочтение open-source компонентам** (FAISS, LangChain, LlamaIndex).

---

## 3. Скоуп проекта / итерации

### 3.1 Входит в скоуп (MVP)
- Развёртывание RAG-системы на локальном хосте.
- Импорт новостного датасета (3+ млн сообщений).
- Создание эмбеддингов всех сообщений.
- Построение векторного индекса (FAISS или аналог).
- Разработка пайплайна:
  1. query → 
  2. поиск по индексу → 
  3. сбор контекстов → 
  4. вызов LLM → 
  5. формирование ответа с цитатами и ссылками.
- Разработка Streamlit интерфейса.
- Логи запросов и простая оценка качества (релевантность контекстов).

### 3.2 Не входит в скоуп (пока)
- Автоматическое обновление новостей из Telegram API в реальном времени.
- Обработка нестандартных типов сообщений (фото, опросы).
- Продвинутая модерация контента.
- Продвинутая аналитика новостей и временных трендов.
- Оркестрация через Docker/Kubernetes (опционально на будущее).

---

## 4. Предпосылки решения

1. У нас есть большой архив сообщений (3+ млн), который нужно эффективно индексировать.  
2. Пользовательские запросы предполагают **семантический поиск**, а не ключевые слова — поэтому индекс должен быть векторным.  
3. Локальная работа требует использования относительно компактных моделей для эмбеддингов и генерации (например, BGE / MiniLM для эмбеддингов, Mistral или Llama-based моделей для LLM).
4. Важно давать **цитаты** — значит, структура контекста должна сохранять ID, ссылку и текст сообщения.
5. Система должна быть объяснима, поэтому результат RAG должен включать не только текст ответа, но и список источников.

---

## 5. Постановка задачи

Разработать локальную RAG-систему, выполняющую следующие задачи:

1. Принять запрос пользователя в интерфейсе Streamlit.
2. Сформировать семантический вектор запроса.
3. Найти N наиболее релевантных новостей в FAISS-индексе.
4. Передать их в LLM для генерации связного ответа.
5. Добавить:
   - короткие цитаты из новостей,
   - ссылки на оригинальные сообщения.
6. Отобразить всё в удобном UI.

Показатели качества (ориентировочно):
- релевантность контекстов (поведенческая оценка),
- компактность ответа,
- устойчивость модели к галлюцинациям.

---

## 6. Блок-схема решения
  
  ┌──────────────────────────┐  
  │   Пользовательский запрос│  
  └──────────────┬───────────┘  
                 ↓  
      ┌─────────────────────┐  
      │  Embedding модели   │  
      │  (запрос → вектор)  │  
      └───────────┬─────────┘  
                  ↓  
       ┌────────────────────┐  
       │   FAISS индекс     │  
       │ (поиск k новостей) │  
       └──────────┬─────────┘  
                  ↓  
      ┌──────────────────────┐  
      │  RAG: сбор контекста │  
      └───────────┬──────────┘  
                  ↓  
      ┌──────────────────────┐  
      │     LLM / модель     │  
      │ (ответ + цитаты)     │  
      └──────────┬───────────┘  
                  ↓  
   ┌─────────────────────────────┐  
   │ Streamlit UI (ответ, ссылки)│  
   └─────────────────────────────┘  
  
to be continued... (по мере непосредственной разработки)
